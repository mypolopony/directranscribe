# ğŸ“¡ Directranscribe

**Directranscribe** is a real-time transcription pipeline that captures audio from a Chrome browser tab, transcribes it using OpenAIâ€™s Whisper model, and stores the results in a local SQLite database for later retrieval and analysis. Itâ€™s ideal for transcribing streamed content like webinars, meetings, or live TV.

---

## ğŸ”§ Features

- ğŸ¤ **Live Audio Capture** from Chrome tabs (via macOS Loopback + `ffmpeg`)
- ğŸ§  **Real-Time Transcription** using Whisper via a FastAPI backend
- ğŸ’¾ **Local Persistence** with SQLite for searchable transcripts
- ğŸ§© **Chrome Extension** for quick control and integration
- ğŸ”¦ **Terminal log preview** via `transcript.log`
- ğŸ³ **Dockerized** for easy setup and reproducibility

---

## ğŸ—ï¸ Project Structure

```
directranscribe/
â”œâ”€â”€ app/                   # FastAPI transcription backend
â”œâ”€â”€ sql/                   # SQLite setup and schema
â”œâ”€â”€ img/                   # App icons and static assets
â”œâ”€â”€ main.py                # Launcher for the full pipeline
â”œâ”€â”€ save_to_db.py          # Handles saving transcription chunks
â”œâ”€â”€ background.js          # Chrome extension background script
â”œâ”€â”€ content.js             # Chrome extension tab content script
â”œâ”€â”€ manifest.json          # Chrome extension metadata
â”œâ”€â”€ stream.html            # Extension interface (popup or tab)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Dockerfile             # Containerized setup
â””â”€â”€ README.md              # Youâ€™re here!
```

---

## ğŸš€ Quickstart

### 1. ğŸ³ Build & Run with Docker

```bash
docker build -t directranscribe .
docker run -p 8000:8000 directranscribe
```

### 2. ğŸ”Š Set Up Loopback Audio (macOS)

To capture browser audio:

- Use [Loopback](https://rogueamoeba.com/loopback/) to create a virtual device that includes Chrome output.
- Set Chromeâ€™s output to this virtual device.
- Confirm with `ffmpeg` that youâ€™re capturing correctly.

### 3. ğŸ§© Install Chrome Extension

- Load `manifest.json` as an **unpacked extension** in Chrome:
  - Visit `chrome://extensions/`
  - Enable **Developer Mode**
  - Click **"Load unpacked"** and select the project root

### 4. â–¶ï¸ Start Transcribing

- Launch the FastAPI backend (`main.py`)
- Use the extension to start capturing
- Transcriptions will be displayed and saved to SQLite automatically

---

## ğŸ§ª Development

### Run Locally (no Docker)

```bash
poetry install  # or `pip install -r requirements.txt`
uvicorn app.main:app --reload
```

---

## ğŸ› ï¸ Advanced CLI Usage

Record from Chrome â†’ transcribe â†’ log every 30 seconds:

```bash
while true; do
  echo "$(date)" >> transcript.log
  ffmpeg -f avfoundation -i ":4" -ac 1 -ar 16000 -t 30 -filter:a "volume=10dB" -y chunk.wav -loglevel quiet
  curl -s -X POST http://localhost:8000/transcribe -F "file=@chunk.wav"     | tee -a transcript.log     | jq -r .transcript     | python3 save_to_db.py "DirectTV"
  echo "---" >> transcript.log
done
```

---

## ğŸ’¾ Database Schema

Initialize with:

```bash
sqlite3 transcripts.db < sql/0_init.sql
```

Example schema:

```sql
CREATE TABLE transcripts (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
  label TEXT,
  transcript TEXT
);
```

Query with:

```bash
sqlite3 transcripts.db "SELECT timestamp, label, transcript FROM transcripts ORDER BY id DESC LIMIT 10;"
```

---

## ğŸ§  Future Ideas

- ğŸ” **Searchable Web UI** for stored transcripts
- ğŸ“¤ Export transcripts as `.txt` or `.srt`
- ğŸŒ OS-agnostic audio capture setup
- ğŸ” Authentication for hosted deployments
- ğŸ·ï¸ Auto-tagging and show detection
- ğŸ¤– Full-text search or LLM summarization

---

## ğŸ“¸ Examples

![example](img/example.png)
![example](img/another_example.png)
---

## Example Text

```
Sun May 25 04:53:34 PDT 2025
 We all work so hard. It's so funny how, like, the racing 
 world and dairy farmers have so much in common. I mean, 
 I feel like we have a pit crew that helps run our farm. I
 mean, it takes a bunch of people just like an Indie car 
 driver does. You know, we're the fourth generation raising 
 the fifth generation. I have two daughters. So to be, this 
 is only the second time two women have been milk presenters
 at the Indianapolis 500. So to be a role model and help 
 inspire our children. We're hoping for that and we're a 
 robot dairy. So we have robots at milk our cows. So we're
 our cow, now.
```

## ğŸ™ Credits

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Loopback Audio](https://rogueamoeba.com/loopback/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [ffmpeg](https://ffmpeg.org/)